{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c140e6eb",
   "metadata": {},
   "source": [
    "Go to this given URL and solve the following questions\n",
    "\n",
    "URL: https://www.youtube.com/@PW-Foundation/videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dec75d",
   "metadata": {},
   "source": [
    "**Q1. Write a python program to extract the video URL of the first five videos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8593b130",
   "metadata": {},
   "source": [
    "I can easily scrape data from `flipkart.com` web page using `requests`, `beautifulsoup` and `urllib` library. But that is not working while I try to scrape data of a `youtube` channel videos. The reasons are:\n",
    "\n",
    "- `Dynamic Content:` Websites like YouTube often load content `dynamically` using `JavaScript`. This means that the `initial HTML` source you receive from the `serve`r might not contain all the data you see on the `fully` loaded page. Instead, `JavaScript` code runs in your browser to fetch `additional` data and populate the page. Libraries like `Requests` and `urllib` don't handle `JavaScript` execution, so they won't capture the complete data.\n",
    "\n",
    "- `AJAX Requests:` YouTube uses `AJAX (Asynchronous JavaScript and XML)` requests to fetch additional data without reloading the entire page. This can make it difficult to scrape data using traditional methods because these requests are made after the `initial page load.` Here, YouTube uses `pagination` and `infinite scrolling` to load more videos as you `scroll down` the page. This means that we need to use a tool that can interact with the web page elements, such as `clicking` on buttons or `scrolling` down the page, to get more data\n",
    "\n",
    "- `Anti-Scraping Measures:` Popular websites like YouTube implement measures to prevent `automated scraping`. They might use techniques like `CAPTCHA` challenges, `rate limiting`, `IP blocking`, or `obfuscated HTML/CSS` to make scraping more difficult.\n",
    "\n",
    "- `APIs:` Many websites, including YouTube, provide `APIs (Application Programming Interfaces)` to access their data in a `structured` and `controlled` manner. These APIs are designed for developers to access data without `scraping`. YouTube has a well-documented `API` that you can use to fetch information about `channels`, `videos`, `comments`, etc.\n",
    "\n",
    "To scrape data from a YouTube channel, we recommend using the `YouTube API` instead of trying to scrape the web page directly. Here's a basic overview of how we can get started using the YouTube API:\n",
    "\n",
    "- `Create a Project and Get API Key:` we need to create a project on the Google `Cloud Platform` and enable the `YouTube API` for that project. This will give you an `API key` that you can use to make `API requests.`\n",
    "\n",
    "- `Make API Requests:` we  can use libraries like `google-api-python-client` to interact with the `YouTube API` using Python. we'll be able to fetch channel `information`, `video details`, `comments`, etc. in a structured format.\n",
    "\n",
    "- `Authentication:` Depending on ouur use case, we might need to set up authentication to ensure we have the necessary `permissions` to access the data.\n",
    "\n",
    "By using the `YouTube API`, we'll be able to retrieve accurate and up-to-date data without worrying about the complexities of `web scraping` and the potential issues it might entail.\n",
    "\n",
    "But there is another method like `Selenium` and `Puppeteer`. These are popular choices for scraping data from websites that heavily rely on JavaScript to load and display content. When it comes to scraping data from YouTube channel videos, these tools can be quite effective, as they can handle the dynamic nature of the website and allow you to interact with the page just like a real user would.\n",
    "\n",
    "Selenium: Selenium is a web automation framework that allows you to control a web browser programmatically. It's commonly used for tasks like testing web applications, automating repetitive tasks, and web scraping. Selenium can work with various web browsers such as Chrome, Firefox, and Edge. You can script interactions like clicking buttons, filling forms, and scrolling down a page to load more content.\n",
    "\n",
    "Pros of using Selenium:\n",
    "\n",
    "It can handle JavaScript-rendered content, making it suitable for websites like YouTube that rely heavily on client-side scripting.\n",
    "You can simulate human-like interactions, which can help bypass some anti-scraping measures.\n",
    "Works well for websites that don't have public APIs or when you need to interact with UI elements that APIs can't access.\n",
    "Cons of using Selenium:\n",
    "\n",
    "Slower compared to API-based approaches since it involves rendering the web page and simulating user actions.\n",
    "Can be more resource-intensive as it requires launching a browser instance.\n",
    "\n",
    "Puppeteer: Puppeteer is a Node.js library developed by Google that provides a high-level API to control headless versions of web browsers (browsers without a visible user interface). It's designed for web scraping, automated testing, and generating screenshots or PDFs of web pages.\n",
    "\n",
    "Pros of using Puppeteer:\n",
    "\n",
    "Offers powerful control over headless browsers, making it efficient for scraping dynamic content.\n",
    "Great for generating screenshots, PDFs, and other web-related tasks.\n",
    "Can be easier to set up and use than Selenium in some cases.\n",
    "Cons of using Puppeteer:\n",
    "\n",
    "Similar to Selenium, it can be slower compared to API-based approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112672e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c246f5",
   "metadata": {},
   "source": [
    "- Install a browser driver that matches our browser and operating system. `Selenium` supports `Chrome`, `Firefox`, `Edge`, `Safari`, and others.\n",
    "- Save the driver executable file in a folder that is in our system path or specify the path when I create a webdriver object. For example, I can run this code in Python to launch Chrome:\n",
    "```python\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=\"C:/path/to/chromedriver.exe\")\n",
    "```\n",
    "- We can Use the `webdriver` object to navigate, interact, and extract data from web pages. But, I will `use BeautifulSoup` to extract data from html content after getting the `dynamic html` content from youtube channel via `selenium`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94e93483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.youtube.com/watch?v=LuTONVLzESM\n",
      "https://www.youtube.com/watch?v=KWXKegvNa-I\n",
      "https://www.youtube.com/watch?v=dArUpCasmnE\n",
      "https://www.youtube.com/watch?v=HqG2QchBw8Y\n",
      "https://www.youtube.com/watch?v=1izKrQHyx9M\n"
     ]
    }
   ],
   "source": [
    "# This is the whole python code in one place to extract the youtube videos url\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# Start a new instance of the Chrome web driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the YouTube channel URL\n",
    "channel_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "driver.get(channel_url)\n",
    "\n",
    "# Scroll down the page by 1000 pixels and wait for 60 seconds\n",
    "# such that complete html content will be loaded atleast for 5 videos\n",
    "driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "time.sleep(60)\n",
    "\n",
    "# We can extract the HTML content from the driver using the page_source method\n",
    "# and store it in youtube_page variable\n",
    "youtube_page = driver.page_source\n",
    "\n",
    "# Close the driver gracefully\n",
    "try:\n",
    "    driver.quit()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Beautify html content such that we can search for exact information\n",
    "youtube_html = BeautifulSoup(youtube_page, 'lxml')\n",
    "# Find the div element of youtube video with specific attributes\n",
    "bigbox = youtube_html.findAll(\"div\", {\"id\": \"content\", \"class\": \"style-scope ytd-rich-item-renderer\"})\n",
    "for i in range(5):\n",
    "    # Exatract the url link for every video on the youtube channel\n",
    "    video_link = \"https://www.youtube.com\" + bigbox[i].div.div.a['href']\n",
    "    # Show the url link\n",
    "    print(video_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7b6d6a",
   "metadata": {},
   "source": [
    "**Q2. Write a python program to extract the URL of the video thumbnails of the first five videos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e721ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://i.ytimg.com/vi/LuTONVLzESM/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLCaMVZmPmUqryYudQm6lobkny_-Cg\n",
      "https://i.ytimg.com/vi/KWXKegvNa-I/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLAZ9XEzNrcu4YfUzbEfohE3CdXIVw\n",
      "https://i.ytimg.com/vi/dArUpCasmnE/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLCdiUURSFwzHKBaqzNQnNYVFf1PZA\n",
      "https://i.ytimg.com/vi/HqG2QchBw8Y/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLB2qRg5GsfQROPt6YiiG3CXXiExjg\n",
      "https://i.ytimg.com/vi/1izKrQHyx9M/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLCvjSUCwD4j5ZVE_nUMLg6QNCpkfg\n"
     ]
    }
   ],
   "source": [
    "# This is the whole python code in one place to extract the url link of the video thumbnail image\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# Start a new instance of the Chrome web driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the YouTube channel URL\n",
    "channel_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "driver.get(channel_url)\n",
    "\n",
    "# Scroll down the page by 1000 pixels and wait for 60 seconds\n",
    "# such that complete html content will be loaded atleast for 5 videos\n",
    "driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "time.sleep(60)\n",
    "\n",
    "# We can extract the HTML content from the driver using the page_source method\n",
    "# and store it in youtube_page variable\n",
    "youtube_page = driver.page_source\n",
    "\n",
    "# Close the driver gracefully\n",
    "try:\n",
    "    driver.quit()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Beautify html content such that we can search for exact information\n",
    "youtube_html = BeautifulSoup(youtube_page, 'lxml')\n",
    "# Find the div element of youtube video with specific attributes\n",
    "bigbox = youtube_html.findAll(\"div\", {\"id\": \"content\", \"class\": \"style-scope ytd-rich-item-renderer\"})\n",
    "for i in range(5):\n",
    "    # Exatract the url link for every video thumbnail image on the youtube channel\n",
    "    video_thumbnail_url = bigbox[i].div.div.a.img['src']\n",
    "    # Show the url link of video thumbnail image\n",
    "    print(video_thumbnail_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aee7025",
   "metadata": {},
   "source": [
    "**Q3. Write a python program to extract the title of the first five videos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34273e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARTS ‡§ï‡•Ä ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•Ä PAHAL üî• || Launching Class 11th ARTS BATCH\n",
      "Something Big Coming Soon For Class - 9th & 10th Students üî• || Stay Tuned For More Updates üñãÔ∏è\n",
      "Launching PAHAL Batch üî• For Class 11th Arts Students üí™\n",
      "Launching FUNDO For Class - 6th to 8th Students üî•üíØ || Ab Hoga Padhai Ke Sath FUN ü§©\n",
      "‚ö°Unleashing the Power of PW Internationally‚ö°| Launching Physics Wallah Gulf\n"
     ]
    }
   ],
   "source": [
    "# This is the whole python code in one place to extract the url link of the video thumbnail image\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# Start a new instance of the Chrome web driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the YouTube channel URL\n",
    "channel_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "driver.get(channel_url)\n",
    "\n",
    "# Scroll down the page by 1000 pixels and wait for 60 seconds\n",
    "# such that complete html content will be loaded atleast for 5 videos\n",
    "driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "time.sleep(60)\n",
    "\n",
    "# We can extract the HTML content from the driver using the page_source method\n",
    "# and store it in youtube_page variable\n",
    "youtube_page = driver.page_source\n",
    "\n",
    "# Close the driver gracefully\n",
    "try:\n",
    "    driver.quit()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Beautify html content such that we can search for exact information\n",
    "youtube_html = BeautifulSoup(youtube_page, 'lxml')\n",
    "# Find the div element of youtube video with specific attributes\n",
    "bigbox = youtube_html.findAll(\"div\", {\"id\": \"meta\", \"class\": \"style-scope ytd-rich-grid-media\"})\n",
    "for i in range(5):\n",
    "    # Exatract the title for every video on the youtube channel\n",
    "    video_title = bigbox[i].a['title']\n",
    "    # Show the url link of video thumbnail image\n",
    "    print(video_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb2b8b3",
   "metadata": {},
   "source": [
    "**Q4. Write a python program to extract the number of views of the first five videos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb814ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19K views\n",
      "41K views\n",
      "34K views\n",
      "27K views\n",
      "71K views\n"
     ]
    }
   ],
   "source": [
    "# This is the whole python code in one place to extract the url link of the video thumbnail image\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# Start a new instance of the Chrome web driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the YouTube channel URL\n",
    "channel_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "driver.get(channel_url)\n",
    "\n",
    "# Scroll down the page by 1000 pixels and wait for 60 seconds\n",
    "# such that complete html content will be loaded atleast for 5 videos\n",
    "driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "time.sleep(60)\n",
    "\n",
    "# We can extract the HTML content from the driver using the page_source method\n",
    "# and store it in youtube_page variable\n",
    "youtube_page = driver.page_source\n",
    "\n",
    "# Close the driver gracefully\n",
    "try:\n",
    "    driver.quit()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Beautify html content such that we can search for exact information\n",
    "youtube_html = BeautifulSoup(youtube_page, 'lxml')\n",
    "# Find the div element of youtube video with specific attributes\n",
    "bigbox = youtube_html.findAll(\"div\", {\"id\": \"metadata-line\", \"class\": \"style-scope ytd-video-meta-block\"})\n",
    "for i in range(5):\n",
    "    # Exatract the html for every div elements in the bigbox list\n",
    "    div_html = BeautifulSoup(str(bigbox[i]), 'lxml')\n",
    "    # Store all the span elements inside a list named span_elements\n",
    "    span_elements = div_html.findAll(\"span\")\n",
    "    # Exatract the views for every video on the youtube channel\n",
    "    video_views = span_elements[0].text\n",
    "    # Show the url link of video thumbnail image\n",
    "    print(video_views)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ccd906",
   "metadata": {},
   "source": [
    "**Q5. Write a python program to extract the time of posting of video for the first five videos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4732559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 weeks ago\n",
      "3 weeks ago\n",
      "1 month ago\n",
      "1 month ago\n",
      "1 month ago\n"
     ]
    }
   ],
   "source": [
    "# This is the whole python code in one place to extract the url link of the video thumbnail image\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# Start a new instance of the Chrome web driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the YouTube channel URL\n",
    "channel_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "driver.get(channel_url)\n",
    "\n",
    "# Scroll down the page by 1000 pixels and wait for 60 seconds\n",
    "# such that complete html content will be loaded atleast for 5 videos\n",
    "driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "time.sleep(60)\n",
    "\n",
    "# We can extract the HTML content from the driver using the page_source method\n",
    "# and store it in youtube_page variable\n",
    "youtube_page = driver.page_source\n",
    "\n",
    "# Close the driver gracefully\n",
    "try:\n",
    "    driver.quit()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Beautify html content such that we can search for exact information\n",
    "youtube_html = BeautifulSoup(youtube_page, 'lxml')\n",
    "# Find the div element of youtube video with specific attributes\n",
    "bigbox = youtube_html.findAll(\"div\", {\"id\": \"metadata-line\", \"class\": \"style-scope ytd-video-meta-block\"})\n",
    "for i in range(5):\n",
    "    # Exatract the html for every div elements in the bigbox list\n",
    "    div_html = BeautifulSoup(str(bigbox[i]), 'lxml')\n",
    "    # Store all the span elements inside a list named span_elements\n",
    "    span_elements = div_html.findAll(\"span\")\n",
    "    # Exatract the views for every video on the youtube channel\n",
    "    video_posting_time = span_elements[1].text\n",
    "    # Show the url link of video thumbnail image\n",
    "    print(video_posting_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b872fbd",
   "metadata": {},
   "source": [
    "`Note: Save all the data scraped in the above questions in a CSV file.`\n",
    "\n",
    "**Save all the data scraped in the above questions like video url link, video thumbnail image link, video title, video views, video posting time in a CSV file  using a python program.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9fa79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_youtube_channel_and_save_to_csv(channel_url, num_videos, output_csv_file):\n",
    "    try:\n",
    "        # Start a new instance of the Chrome web driver\n",
    "        driver = webdriver.Chrome()\n",
    "        \n",
    "        # Open the YouTube channel URL\n",
    "        driver.get(channel_url)\n",
    "        \n",
    "        # Scroll down the page by 1000 pixels and wait for 60 seconds\n",
    "        # so that complete HTML content will be loaded for at least num_videos\n",
    "        driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "        time.sleep(60)\n",
    "        \n",
    "        # Extract the HTML content from the driver using the page_source method\n",
    "        # and store it in youtube_page variable\n",
    "        youtube_page = driver.page_source\n",
    "        \n",
    "        # Close the driver gracefully\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "        # Beautify html content such that we can search for exact information\n",
    "        youtube_html = BeautifulSoup(youtube_page, 'lxml')\n",
    "        \n",
    "        # Find the div elements containing video information\n",
    "        video_items = youtube_html.findAll(\"div\", {\"id\": \"dismissible\"})\n",
    "        \n",
    "        # Prepare data for CSV\n",
    "        csv_data = []\n",
    "        for i in range(min(num_videos, len(video_items))):\n",
    "            \n",
    "            # Extract video title\n",
    "            video_title = youtube_html.findAll(\"a\", {\"id\": \"video-title-link\"})[i]['title']\n",
    "            \n",
    "            # Extract video views\n",
    "            video_views = youtube_html.findAll(\"div\", {\"id\": \"metadata-line\"})[i].findAll(\"span\")[0].text\n",
    "            \n",
    "            # Extract video posting time\n",
    "            video_posting_time = youtube_html.findAll(\"div\", {\"id\": \"metadata-line\"})[i].findAll(\"span\")[1].text\n",
    "            \n",
    "            # Extract video URL link\n",
    "            video_url = \"https://www.youtube.com\" + youtube_html.findAll(\"div\", {\"id\": \"thumbnail\"})[i].a['href']\n",
    "            \n",
    "            # Extract video thumbnail image link\n",
    "            video_thumbnail_link = youtube_html.findAll(\"div\", {\"id\": \"thumbnail\"})[i].a.img['src']\n",
    "            \n",
    "            # Append data to CSV list\n",
    "            csv_data.append({\n",
    "                \"Video Title\": video_title,\n",
    "                \"Video Views\": video_views,\n",
    "                \"Video Posting Time\": video_posting_time,\n",
    "                \"Video URL\": video_url,\n",
    "                \"Thumbnail Link\": video_thumbnail_link\n",
    "            })\n",
    "        \n",
    "        # Save data to CSV file\n",
    "        with open(output_csv_file, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "            csv_writer = csv.DictWriter(csv_file, fieldnames=[\"Video Title\", \"Video Views\", \"Video Posting Time\", \"Video URL\", \"Thumbnail Link\"])\n",
    "            csv_writer.writeheader()\n",
    "            csv_writer.writerows(csv_data)\n",
    "        \n",
    "        print(f\"Scraped and saved data for {len(csv_data)} videos to {output_csv_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Define the YouTube channel URL\n",
    "channel_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Define the number of videos to scrape\n",
    "num_videos_to_scrape = 5\n",
    "\n",
    "# Define the output CSV file name\n",
    "output_csv_file = \"youtube_data.csv\"\n",
    "\n",
    "# Call the function to scrape and save data to CSV\n",
    "scrape_youtube_channel_and_save_to_csv(channel_url, num_videos_to_scrape, output_csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30df8f24",
   "metadata": {},
   "source": [
    "**How to show the data from youtube_data.csv ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e89f240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Video Title Video Views  \\\n",
      "0  ARTS ‡§ï‡•Ä ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•Ä PAHAL üî• || Launching Class 1...   19K views   \n",
      "1  Something Big Coming Soon For Class - 9th & 10...   41K views   \n",
      "2  Launching PAHAL Batch üî• For Class 11th Arts St...   35K views   \n",
      "3  Launching FUNDO For Class - 6th to 8th Student...   27K views   \n",
      "4  ‚ö°Unleashing the Power of PW Internationally‚ö°| ...   71K views   \n",
      "\n",
      "  Video Posting Time                                    Video URL  \\\n",
      "0        2 weeks ago  https://www.youtube.com/watch?v=LuTONVLzESM   \n",
      "1        3 weeks ago  https://www.youtube.com/watch?v=KWXKegvNa-I   \n",
      "2        1 month ago  https://www.youtube.com/watch?v=dArUpCasmnE   \n",
      "3        1 month ago  https://www.youtube.com/watch?v=HqG2QchBw8Y   \n",
      "4        1 month ago  https://www.youtube.com/watch?v=1izKrQHyx9M   \n",
      "\n",
      "                                      Thumbnail Link  \n",
      "0  https://i.ytimg.com/vi/LuTONVLzESM/hqdefault.j...  \n",
      "1  https://i.ytimg.com/vi/KWXKegvNa-I/hqdefault.j...  \n",
      "2  https://i.ytimg.com/vi/dArUpCasmnE/hqdefault.j...  \n",
      "3  https://i.ytimg.com/vi/HqG2QchBw8Y/hqdefault.j...  \n",
      "4  https://i.ytimg.com/vi/1izKrQHyx9M/hqdefault.j...  \n"
     ]
    }
   ],
   "source": [
    "# show the data from youtube_data.csv in our notebook\n",
    "import pandas as pd\n",
    "\n",
    "def show_youtube_data(csv_file):\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        data = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Display the data\n",
    "        print(data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Define the CSV file to show\n",
    "csv_file = \"youtube_data.csv\"\n",
    "\n",
    "# Call the function to show data\n",
    "show_youtube_data(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81c65ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Title: ARTS ‡§ï‡•Ä ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•Ä PAHAL üî• || Launching Class 11th ARTS BATCH, Views: 19K views, Posting Time: 2 weeks ago, URL: https://www.youtube.com/watch?v=LuTONVLzESM, Thumbnail Link: https://i.ytimg.com/vi/LuTONVLzESM/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLCaMVZmPmUqryYudQm6lobkny_-Cg\n",
      "Video Title: Something Big Coming Soon For Class - 9th & 10th Students üî• || Stay Tuned For More Updates üñãÔ∏è, Views: 41K views, Posting Time: 3 weeks ago, URL: https://www.youtube.com/watch?v=KWXKegvNa-I, Thumbnail Link: https://i.ytimg.com/vi/KWXKegvNa-I/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLAZ9XEzNrcu4YfUzbEfohE3CdXIVw\n",
      "Video Title: Launching PAHAL Batch üî• For Class 11th Arts Students üí™, Views: 35K views, Posting Time: 1 month ago, URL: https://www.youtube.com/watch?v=dArUpCasmnE, Thumbnail Link: https://i.ytimg.com/vi/dArUpCasmnE/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLCdiUURSFwzHKBaqzNQnNYVFf1PZA\n",
      "Video Title: Launching FUNDO For Class - 6th to 8th Students üî•üíØ || Ab Hoga Padhai Ke Sath FUN ü§©, Views: 27K views, Posting Time: 1 month ago, URL: https://www.youtube.com/watch?v=HqG2QchBw8Y, Thumbnail Link: https://i.ytimg.com/vi/HqG2QchBw8Y/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLB2qRg5GsfQROPt6YiiG3CXXiExjg\n",
      "Video Title: ‚ö°Unleashing the Power of PW Internationally‚ö°| Launching Physics Wallah Gulf, Views: 71K views, Posting Time: 1 month ago, URL: https://www.youtube.com/watch?v=1izKrQHyx9M, Thumbnail Link: https://i.ytimg.com/vi/1izKrQHyx9M/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&rs=AOn4CLCvjSUCwD4j5ZVE_nUMLg6QNCpkfg\n"
     ]
    }
   ],
   "source": [
    "# show the data from youtube_data.csv in our notebook in another way\n",
    "import csv\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_file_path = \"youtube_data.csv\"\n",
    "\n",
    "# Function to display data in a single line\n",
    "def display_video_data(video_data):\n",
    "    print(f\"Video Title: {video_data['Video Title']}, Views: {video_data['Video Views']}, Posting Time: {video_data['Video Posting Time']}, URL: {video_data['Video URL']}, Thumbnail Link: {video_data['Thumbnail Link']}\")\n",
    "\n",
    "# Read the CSV file and display data\n",
    "with open(csv_file_path, newline='', encoding='utf-8') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        display_video_data(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576db13d",
   "metadata": {},
   "source": [
    "**Create a simple UI with all functionalities mentioned above and deploy it in AWS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5821206b",
   "metadata": {},
   "source": [
    "Building a full UI and deploying it to AWS involves several steps, including frontend development, backend development, and deployment. Here's an outline of the process:\n",
    "\n",
    "- Frontend Development: We need to create a user interface where users can interact with your application. Since you mentioned a \"simple\" UI, I'll assume a basic web-based interface. We can use HTML, CSS, and JavaScript for this purpose. We can give input like channel url and num of videos to scrape as like form text in our `Scrape page`. If we press the submit button, then the input will be sended to our `application.py` file.\n",
    "\n",
    "- Backend Development: We'll use Flask (a lightweight Python web framework) to handle the requests from the frontend and perform the scraping task. Then data will be displayed in `/show` page with the help of `results.html`. \n",
    "\n",
    "- Deployment on AWS: We'll deploy the Flask application to an AWS using CodePipeline and elastic beanstalk. This will require creating an Elastic beanstalk instance, setting up the necessary environment, and deploying the Flask app.\n",
    "\n",
    "Let's start with the code:\n",
    "\n",
    "- Frontend (HTML): Create a simple HTML form where the user can input the YouTube channel URL and the number of videos to scrape. Include a button to submit the form. Create a folder with name `Youtube_Data_scraper` as our project for youtube channel video data scraping. Inside that folder, Under `templates` folder we have craeted `base.html`,`index.html` and `results.html` files.\n",
    "\n",
    "**index.html**\n",
    "```html\n",
    "<!-- This line extends a base HTML template named 'base.html'. -->\n",
    "<!-- It means this file will inherit the content from the 'base.html' template. -->\n",
    "{% extends 'base.html' %}\n",
    "\n",
    "<!-- This block is named 'head' and it overrides the 'head' block in the 'base.html' template. -->\n",
    "{% block head %}\n",
    "\n",
    "<!-- This line sets the title of the web page to 'Scrape Youtube Data Page'. -->\n",
    "<title>Scrape Youtube Data Page</title>\n",
    "\n",
    "<!-- This line links to an external stylesheet, but the link is empty (\"href=\"\"\") meaning no specific CSS file is being linked. -->\n",
    "<!-- You can fill in the href attribute with the URL of a CSS file to style the page. -->\n",
    "<link rel=\"stylesheet\" href=\"{{ url_for('static', filename='css/style.css') }}\">\n",
    "{% endblock %}\n",
    "\n",
    "<!-- This block is named 'body' and it overrides the 'body' block in the 'base.html' template. -->\n",
    "{% block body %}\n",
    "\n",
    "<!-- This <div> element has a class attribute set to 'content', which can be used for styling. -->\n",
    "<div class=\"content\">\n",
    "\n",
    "    <!-- This <h1> heading element has its text centered with the style attribute. -->\n",
    "    <h1 style=\"text-align: center\">Youtube Data Scraper</h1>\n",
    "\n",
    "    <!-- This <div> element has a class attribute set to 'form', which can be used for styling. -->\n",
    "    <div class=\"form\">\n",
    "\n",
    "        <!-- This <form> element is used to create a scrape form. -->\n",
    "        <!-- It has an 'action' attribute set to '/scrape', which means the form will be submitted to the '/scrape' URL on form submission. -->\n",
    "        <!-- The 'method' attribute is set to 'POST', indicating that the form data will be sent to the server using the HTTP POST method. -->\n",
    "        <form action=\"/scrape\" method=\"POST\">\n",
    "             \n",
    "            <!-- It will be used to enter the channel_url and num of videos to scrape. -->\n",
    "            <label for=\"channel_url\">Channel URL:</label>\n",
    "            <input type=\"text\" id=\"channel_url\" name=\"channel_url\"><br><br>\n",
    "\n",
    "            <label for=\"num_videos\">Number of Videos:</label>\n",
    "            <input type=\"number\" id=\"num_videos\" name=\"num_videos\"><br><br>\n",
    "\n",
    "            <!-- This <input> element is of type 'submit' and has its value set to 'Scrape'. -->\n",
    "            <!-- It will be used as the submit button for the form. -->\n",
    "            <input type=\"submit\" value=\"Scrape\">\n",
    "        </form>\n",
    "    </div>\n",
    "</div>\n",
    "{% endblock %}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20abf1a",
   "metadata": {},
   "source": [
    "**base.html**\n",
    "```html\n",
    "<!-- This line specifies the document type and version of HTML being used. -->\n",
    "<!DOCTYPE html>\n",
    "\n",
    "<!-- This line starts the HTML document and specifies the language as English. -->\n",
    "<html lang=\"en\">\n",
    "\n",
    "<head>\n",
    "    <!-- This line sets the character encoding to UTF-8, which supports various characters and symbols. -->\n",
    "    <meta charset=\"UTF-8\">\n",
    "\n",
    "    <!-- This line sets the viewport properties, allowing the page to adjust its layout to fit different screen sizes. -->\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "\n",
    "    <!-- This line defines the compatibility mode for Internet Explorer. -->\n",
    "    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n",
    "\n",
    "    <!-- This line links to an external stylesheet, but the link is empty (\"href=\"\"\") meaning no specific CSS file is being linked. -->\n",
    "    <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='css/main.css') }}\">\n",
    "\n",
    "    <!-- This is a placeholder for a block of content that can be filled in later. -->\n",
    "    <!-- In certain web frameworks, like Django, this allows for reusable templates. -->\n",
    "    <!-- It's common to override this block in other HTML files that extend this template. -->\n",
    "    {% block head %}{% endblock %}\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "    <!-- This is another placeholder for a block of content that can be filled in later. -->\n",
    "    <!-- Similar to the previous block, it's used for extending and overriding templates. -->\n",
    "    {% block body %}{% endblock %}\n",
    "</body>\n",
    "\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a18155",
   "metadata": {},
   "source": [
    "**results.html**\n",
    "```html\n",
    "<!-- This line specifies the document type and version of HTML being used. -->\n",
    "<!DOCTYPE html>\n",
    "\n",
    "<!-- This line starts the HTML document and specifies the language as English. -->\n",
    "<html lang=\"en\">\n",
    "\n",
    "<head>\n",
    "    <!-- This line sets the character encoding to UTF-8, which supports various characters and symbols. -->\n",
    "    <meta charset=\"UTF-8\">\n",
    "\n",
    "    <!-- This line sets the title of the web page to \"Scraped Data\". -->\n",
    "    <title>Scraped YouTube Data</title>\n",
    "\n",
    "    <!-- This line links to an external stylesheet from the 'cdnjs' content delivery network (CDN). -->\n",
    "    <!-- It loads the 'normalize.min.css' file, which helps to standardize styles across different browsers. -->\n",
    "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css\">\n",
    "\n",
    "    <!-- This line links to a local stylesheet named 'style.css' in the same directory as this HTML file. -->\n",
    "    <!-- It is used to provide custom styles for the page. -->\n",
    "    <link rel=\"stylesheet\" href=\"./style.css\">\n",
    "\n",
    "    <!-- This line links to an empty external stylesheet. -->\n",
    "    <!-- It means no specific CSS file is being linked. -->\n",
    "    <!-- You can fill in the href attribute with the URL of another CSS file if needed. -->\n",
    "    <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='css/style.css') }}\">\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "    <!-- This <div> element has a class attribute set to 'table-users'. -->\n",
    "    <!-- It can be used for styling or selecting this element using CSS or JavaScript. -->\n",
    "    <div class=\"table-users\">\n",
    "        <!-- This <div> element has a class attribute set to 'header'. -->\n",
    "        <!-- It can be used for styling or selecting this element using CSS or JavaScript. -->\n",
    "        <div class=\"header\">Scraped YouTube Data</div>\n",
    "\n",
    "        <!-- This <table> element is used to create a table to display scraped data. -->\n",
    "        <!-- The 'cellspacing' attribute sets the space between table cells to 0. -->\n",
    "        <table cellspacing=\"0\">\n",
    "            <!-- This <tr> element represents a table row and contains table headings (th). -->\n",
    "            <tr>\n",
    "                <!-- This <th> element represents a table header cell for the \"Video Title\" column. -->\n",
    "                <th width=\"230\">Video Title</th>\n",
    "\n",
    "                <!-- This <th> element represents a table header cell for the \"Video Views\" column. -->\n",
    "                <th>Video Views</th>\n",
    "\n",
    "                <!-- This <th> element represents a table header cell for the \"Video Posting Time\" column. -->\n",
    "                <th>Video Posting Time</th>\n",
    "\n",
    "                <!-- This <th> element represents a table header cell for the \"Video URL\" column. -->\n",
    "                <th>Video URL</th>\n",
    "\n",
    "                <!-- This <th> element represents a table header cell for the \"Thumbnail Link\" column. -->\n",
    "                <th>Thumbnail Link</th>\n",
    "\n",
    "            </tr>\n",
    "\n",
    "                <!-- This is a placeholder for a loop that iterates over a CSV file. -->\n",
    "                <!-- The loop is using a template engine like Jinja, Django, or similar. -->\n",
    "                <!-- The loop will generate table rows (tr) for each data row inside the CSV file. -->\n",
    "                {% for index, row in data.iterrows() %}\n",
    "            <tr>\n",
    "                <!-- These <td> elements represent table data cells, used to display youtube video details. -->\n",
    "                <!-- This is where the video details (title, Views, Posting time, URL, Thumbnail Link) would be inserted when the loop runs. -->\n",
    "                <td>{{ row['Video Title'] }}</td>\n",
    "                <td>{{ row['Video Views'] }}</td>\n",
    "                <td>{{ row['Video Posting Time'] }}</td>\n",
    "                <td><a href=\"{{ row['Video URL'] }}\" target=\"_blank\">{{ row['Video URL'] }}</a></td>\n",
    "                <td><a href=\"{{ row['Thumbnail Link'] }}\" target=\"_blank\"><img src=\"{{ row['Thumbnail Link'] }}\" alt=\"{{ row['Video Title'] }}\"></a></td>\n",
    "            </tr>\n",
    "                {% endfor %}\n",
    "        </table>\n",
    "    </div>\n",
    "</body>\n",
    "\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e8da6",
   "metadata": {},
   "source": [
    "Under `static\\css` folder, we have two files `main.css` and `style.css`:\n",
    "\n",
    "**main.css**\n",
    "```css\n",
    "/* CSS code for styling the page */\n",
    "\n",
    "/* Set margin and font-family for body and html elements */\n",
    "body, html {\n",
    "    margin: 0;\n",
    "    font-family: sans-serif;\n",
    "}\n",
    "\n",
    "/* Set margin and width for elements with the class \"content\" */\n",
    ".content {\n",
    "    margin: 0 auto; /* Center the element horizontally */\n",
    "    width: 400px;   /* Set the width to 400 pixels */\n",
    "}\n",
    "\n",
    "/* Apply border to table, table cells (td), and table header cells (th) */\n",
    "table, td, th {\n",
    "    border: 1px solid #aaa; /* Set a 1-pixel solid border with color #aaa */\n",
    "}\n",
    "\n",
    "/* Set border-collapse and width for tables */\n",
    "table {\n",
    "    border-collapse: collapse; /* Collapse table borders into a single border */\n",
    "    width: 100%;               /* Set the table width to 100% of its container */\n",
    "}\n",
    "\n",
    "/* Set height for table header cells (th) */\n",
    "th {\n",
    "    height: 30px; /* Set the height of table header cells to 30 pixels */\n",
    "}\n",
    "\n",
    "/* Center text and add padding to table cells (td) */\n",
    "td {\n",
    "    text-align: center; /* Center the text inside table cells */\n",
    "    padding: 5px;       /* Add 5 pixels of padding around the cell content */\n",
    "}\n",
    "\n",
    "/* Apply margin to elements with the class \"form\" */\n",
    ".form {\n",
    "    margin-top: 20px; /* Add a top margin of 20 pixels */\n",
    "}\n",
    "\n",
    "/* Set width for the element with the ID \"content\" */\n",
    "#content {\n",
    "    width: 70%; /* Set the width to 70% of its container */\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2252b7",
   "metadata": {},
   "source": [
    "**style.css**\n",
    "```css\n",
    "/* Set the background color of the entire page to a light blue shade (#91ced4). */\n",
    "body {\n",
    "  background-color: #91ced4;\n",
    "}\n",
    "\n",
    "/* Apply box-sizing: border-box to all elements within the body. */\n",
    "/* This ensures that padding and border widths are included in the element's total width and height. */\n",
    "body * {\n",
    "  box-sizing: border-box;\n",
    "}\n",
    "\n",
    "/* Style the header element with a dark blue background (#327a81), white text color, and other properties. */\n",
    ".header {\n",
    "  background-color: #327a81;\n",
    "  color: white;\n",
    "  font-size: 1.5em;\n",
    "  padding: 1rem;\n",
    "  text-align: center;\n",
    "  text-transform: uppercase;\n",
    "}\n",
    "\n",
    "/* Style all img elements with a border radius of 50%, and set their height and width to 60px. */\n",
    "img {\n",
    "  border-radius: 50%;\n",
    "  height: 60px;\n",
    "  width: 60px;\n",
    "}\n",
    "\n",
    "/* Style the container div for the table with a border, border radius, box shadow, and max-width of 800px. */\n",
    ".table-users {\n",
    "  border: 1px solid #327a81;\n",
    "  border-radius: 10px;\n",
    "  box-shadow: 3px 3px 0 rgba(0, 0, 0, 0.1);\n",
    "  max-width: calc(100% - 2em);\n",
    "  margin: 1em auto;\n",
    "  overflow: hidden;\n",
    "  width: 800px;\n",
    "}\n",
    "\n",
    "/* Set the width of the table to 100% and style the table cells (td) and table headers (th). */\n",
    "table {\n",
    "  width: 100%;\n",
    "}\n",
    "table td, table th {\n",
    "  color: #2b686e;\n",
    "  padding: 10px;\n",
    "}\n",
    "table td {\n",
    "  text-align: center;\n",
    "  vertical-align: middle;\n",
    "}\n",
    "table td:last-child {\n",
    "  font-size: 0.95em;\n",
    "  line-height: 1.4;\n",
    "  text-align: left;\n",
    "}\n",
    "table th {\n",
    "  background-color: #daeff1;\n",
    "  font-weight: 300;\n",
    "}\n",
    "\n",
    "/* Apply alternating background colors to table rows to create a striped effect. */\n",
    "table tr:nth-child(2n) {\n",
    "  background-color: white;\n",
    "}\n",
    "table tr:nth-child(2n+1) {\n",
    "  background-color: #edf7f8;\n",
    "}\n",
    "\n",
    "/* Media query for screens with a maximum width of 700px. */\n",
    "/* Apply responsive styles to reformat the table for smaller screens. */\n",
    "@media screen and (max-width: 700px) {\n",
    "  /* Set the display property of table, table rows (tr), and table cells (td) to block. */\n",
    "  table, tr, td {\n",
    "    display: block;\n",
    "  }\n",
    "\n",
    "  /* Style the first cell (td) in each row to position it absolutely at the center, and set its width to 100px. */\n",
    "  td:first-child {\n",
    "    position: absolute;\n",
    "    top: 50%;\n",
    "    -webkit-transform: translateY(-50%);\n",
    "    transform: translateY(-50%);\n",
    "    width: 100px;\n",
    "  }\n",
    "\n",
    "  /* Style all cells (td) except the first one to clear both, add left margin, set padding, and align left. */\n",
    "  td:not(:first-child) {\n",
    "    clear: both;\n",
    "    margin-left: 100px;\n",
    "    padding: 4px 20px 4px 90px;\n",
    "    position: relative;\n",
    "    text-align: left;\n",
    "  }\n",
    "\n",
    "  /* Pseudo element styling to add labels (before content) to each cell (td). */\n",
    "  td:not(:first-child):before {\n",
    "    color: #91ced4;\n",
    "    content: '';\n",
    "    display: block;\n",
    "    left: 0;\n",
    "    position: absolute;\n",
    "  }\n",
    "\n",
    "  /* Add specific labels before each cell (td) based on their position in the table. */\n",
    "  td:nth-child(2):before {\n",
    "    content: 'Name:';\n",
    "  }\n",
    "  td:nth-child(3):before {\n",
    "    content: 'Email:';\n",
    "  }\n",
    "  td:nth-child(4):before {\n",
    "    content: 'Phone:';\n",
    "  }\n",
    "  td:nth-child(5):before {\n",
    "    content: 'Comments:';\n",
    "  }\n",
    "\n",
    "  /* Style each row (tr) to add padding and set its position to relative. */\n",
    "  tr {\n",
    "    padding: 10px 0;\n",
    "    position: relative;\n",
    "  }\n",
    "\n",
    "  /* Hide the first row (header row) since it is not needed for the responsive design. */\n",
    "  tr:first-child {\n",
    "    display: none;\n",
    "  }\n",
    "}\n",
    "\n",
    "/* Media query for screens with a maximum width of 500px. */\n",
    "/* Apply additional responsive styles to reformat the table for even smaller screens. */\n",
    "@media screen and (max-width: 500px) {\n",
    "  /* Modify the styling of the header element for smaller screens. */\n",
    "  .header {\n",
    "    background-color: transparent;\n",
    "    color: white;\n",
    "    font-size: 2em;\n",
    "    font-weight: 700;\n",
    "    padding: 0;\n",
    "    text-shadow: 2px 2px 0 rgba(0, 0, 0, 0.1);\n",
    "  }\n",
    "\n",
    "  /* Modify the styling of images for smaller screens. */\n",
    "  img {\n",
    "    border: 3px solid;\n",
    "    border-color: #daeff1;\n",
    "    height: 100px;\n",
    "    margin: 0.5rem 0;\n",
    "    width: 100px;\n",
    "  }\n",
    "\n",
    "  /* Style the first cell (td) in each row for smaller screens. */\n",
    "  td:first-child {\n",
    "    background-color: #c8e7ea;\n",
    "    border-bottom: 1px solid #91ced4;\n",
    "    border-radius: 10px 10px 0 0;\n",
    "    position: relative;\n",
    "    top: 0;\n",
    "    -webkit-transform: translateY(0);\n",
    "    transform: translateY(0);\n",
    "    width: 100%;\n",
    "  }\n",
    "\n",
    "  /* Modify the styling of all cells (td) except the first one for smaller screens. */\n",
    "  td:not(:first-child) {\n",
    "    margin: 0;\n",
    "    padding: 5px 1em;\n",
    "    width: 100%;\n",
    "  }\n",
    "\n",
    "  /* Pseudo element styling for smaller screens to adjust label appearance. */\n",
    "  td:not(:first-child):before {\n",
    "    font-size: .8em;\n",
    "    padding-top: 0.3em;\n",
    "    position: relative;\n",
    "  }\n",
    "\n",
    "  /* Adjust the padding of the last cell (td) for smaller screens. */\n",
    "  td:last-child {\n",
    "    padding-bottom: 1rem !important;\n",
    "  }\n",
    "\n",
    "  /* Modify the styling of table rows (tr) for smaller screens. */\n",
    "  tr {\n",
    "    background-color: white !important;\n",
    "    border: 1px solid #6cbec6;\n",
    "    border-radius: 10px;\n",
    "    box-shadow: 2px 2px 0 rgba(0, 0, 0, 0.1);\n",
    "    margin: 0.5rem 0;\n",
    "    padding: 0;\n",
    "  }\n",
    "\n",
    "  /* Remove border and box shadow from the table container for smaller screens. */\n",
    "  .table-users {\n",
    "    border: none;\n",
    "    box-shadow: none;\n",
    "    overflow: visible;\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb68b2ee",
   "metadata": {},
   "source": [
    "- Backend (Python with Flask):\n",
    "\n",
    "```python\n",
    "# Import necessary modules from Flask and other libraries.\n",
    "from flask import Flask, render_template, request, redirect\n",
    "from flask_cors import CORS, cross_origin\n",
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize a Flask app.\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define the route for the home page\n",
    "@app.route('/', methods=['GET'])\n",
    "@cross_origin()\n",
    "def homePage():\n",
    "    return render_template('index.html')\n",
    "\n",
    "# Define the route to handle the form submission\n",
    "@app.route('/scrape', methods=['POST', 'GET'])\n",
    "@cross_origin()\n",
    "def scrape_youtube():\n",
    "    if request.method == 'POST':\n",
    "        try:\n",
    "            channel_url = request.form['channel_url']\n",
    "            num_videos = int(request.form['num_videos'])\n",
    "            output_csv_file = \"youtube_data.csv\"\n",
    "        \n",
    "            # Call the existing function to scrape and save data to CSV\n",
    "            scrape_youtube_channel_and_save_to_csv(channel_url, num_videos, output_csv_file)\n",
    "        \n",
    "            # Redirect to the page showing the scraped data\n",
    "            return redirect('/show')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print('The Exception message is: ', e)\n",
    "            return 'something is wrong'\n",
    "\n",
    "    else:\n",
    "        # Render the 'index.html' template for the GET request.\n",
    "        return render_template('index.html')\n",
    "    \n",
    "\n",
    "# Define the route to show the scraped data in a web UI.\n",
    "@app.route('/show')\n",
    "@cross_origin()\n",
    "def show_data():\n",
    "    try:\n",
    "        data = pd.read_csv('youtube_data.csv')\n",
    "        return render_template('results.html', data=data)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# This is the same function you provided for scraping and saving data to CSV\n",
    "# I'll include it here to ensure it's part of the Flask app\n",
    "def scrape_youtube_channel_and_save_to_csv(channel_url, num_videos, output_csv_file):\n",
    "    # ... (include our existing scraping code here)\n",
    "    try:\n",
    "        # Start a new instance of the Chrome web driver\n",
    "        driver = webdriver.Chrome()\n",
    "        \n",
    "        # Open the YouTube channel URL\n",
    "        driver.get(channel_url)\n",
    "        \n",
    "        # Scroll down the page by 1000 pixels and wait for 60 seconds\n",
    "        # so that complete HTML content will be loaded for at least num_videos\n",
    "        driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "        time.sleep(60)\n",
    "        \n",
    "        # Extract the HTML content from the driver using the page_source method\n",
    "        # and store it in youtube_page variable\n",
    "        youtube_page = driver.page_source\n",
    "        \n",
    "        # Close the driver gracefully\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "        # Beautify html content such that we can search for exact information\n",
    "        youtube_html = BeautifulSoup(youtube_page, 'lxml')\n",
    "        \n",
    "        # Find the div elements containing video information\n",
    "        video_items = youtube_html.findAll(\"div\", {\"id\": \"dismissible\"})\n",
    "        \n",
    "        # Prepare data for CSV\n",
    "        csv_data = []\n",
    "        for i in range(min(num_videos, len(video_items))):\n",
    "            \n",
    "            # Extract video title\n",
    "            video_title = youtube_html.findAll(\"a\", {\"id\": \"video-title-link\"})[i]['title']\n",
    "            \n",
    "            # Extract video views\n",
    "            video_views = youtube_html.findAll(\"div\", {\"id\": \"metadata-line\"})[i].findAll(\"span\")[0].text\n",
    "            \n",
    "            # Extract video posting time\n",
    "            video_posting_time = youtube_html.findAll(\"div\", {\"id\": \"metadata-line\"})[i].findAll(\"span\")[1].text\n",
    "            \n",
    "            # Extract video URL link\n",
    "            video_url = \"https://www.youtube.com\" + youtube_html.findAll(\"div\", {\"id\": \"thumbnail\"})[i].a['href']\n",
    "            \n",
    "            # Extract video thumbnail image link\n",
    "            video_thumbnail_link = youtube_html.findAll(\"div\", {\"id\": \"thumbnail\"})[i].a.img['src']\n",
    "            \n",
    "            # Append data to CSV list\n",
    "            csv_data.append({\n",
    "                \"Video Title\": video_title,\n",
    "                \"Video Views\": video_views,\n",
    "                \"Video Posting Time\": video_posting_time,\n",
    "                \"Video URL\": video_url,\n",
    "                \"Thumbnail Link\": video_thumbnail_link\n",
    "            })\n",
    "        \n",
    "        # Save data to CSV file\n",
    "        with open(output_csv_file, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "            csv_writer = csv.DictWriter(csv_file, fieldnames=[\"Video Title\", \"Video Views\", \"Video Posting Time\", \"Video URL\", \"Thumbnail Link\"])\n",
    "            csv_writer.writeheader()\n",
    "            csv_writer.writerows(csv_data)\n",
    "        \n",
    "        print(f\"Scraped and saved data for {len(csv_data)} videos to {output_csv_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Start the Flask application on localhost at port 8000 in debug mode.\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='127.0.0.1', port=8000, debug=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999294e",
   "metadata": {},
   "source": [
    "**requirements.txt**\n",
    "```\n",
    "beautifulsoup4==4.9.1\n",
    "bs4==0.0.1\n",
    "certifi==2020.6.20\n",
    "chardet==3.0.4\n",
    "click==7.1.2\n",
    "Flask==1.1.2\n",
    "Flask-Cors==3.0.9\n",
    "gunicorn==20.0.4\n",
    "idna==2.10\n",
    "itsdangerous==1.1.0\n",
    "Jinja2==2.11.2\n",
    "MarkupSafe==1.1.1\n",
    "requests==2.24.0\n",
    "six==1.15.0\n",
    "soupsieve==2.0.1\n",
    "urllib3==1.25.10\n",
    "Werkzeug==1.0.1\n",
    "selenium\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedf3035",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "This project involves creating a web application using Flask to scrape YouTube video data. The application has three main routes: the `home page (/)`, the route for handling form submission `(/scrape)`, and the route for displaying scraped data `(/show)`. The user provides a YouTube channel `URL` and the number of videos to scrape. The `scrape_youtube()` function uses Selenium and Beautiful Soup to scrape video data from the specified channel. The data is then saved to a `youtube_data.csv` file. The scraped data is displayed in a tabular format on the `/show` route. The application uses `Flask` templates to render HTML pages and follows a clear structure to achieve the scraping and data presentation functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92768d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
